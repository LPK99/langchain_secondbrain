{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "09cb99cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "os.environ[\"OPENAI_API_KEY\"] = \"your_api_key\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "9bd1df31",
   "metadata": {},
   "outputs": [],
   "source": [
    "from PyPDF2 import PdfReader\n",
    "from langchain.embeddings.openai import OpenAIEmbeddings\n",
    "from langchain.text_splitter import CharacterTextSplitter\n",
    "from langchain.vectorstores import FAISS "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "0cbcdf57",
   "metadata": {},
   "outputs": [],
   "source": [
    "# location of the pdf file/files. \n",
    "doc_reader = PdfReader('attention-is-all-you-need-Paper.pdf')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "14a84ea4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Attention Is All You Need\\nAshish Vaswani\\x03\\nGoogle Brain\\navaswani@google.comNoam Shazeer\\x03\\nGoogle Brain'"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# read data from the file and put them into a variable called raw_text\n",
    "raw_text = ''\n",
    "for i, page in enumerate(doc_reader.pages):\n",
    "    text = page.extract_text()\n",
    "    if text:\n",
    "        raw_text += text\n",
    "len(raw_text)\n",
    "raw_text[:100]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "5d9a0793",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "41"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Splitting up the text into smaller chunks for indexing\n",
    "text_splitter = CharacterTextSplitter(        \n",
    "    separator = \"\\n\",\n",
    "    chunk_size = 1000,\n",
    "    chunk_overlap  = 200, #striding over the text\n",
    "    length_function = len,\n",
    ")\n",
    "texts = text_splitter.split_text(raw_text)\n",
    "len(texts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "07a439af",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'during training.\\n4 Why Self-Attention\\nIn this section we compare various aspects of self-attention layers to the recurrent and convolu-\\ntional layers commonly used for mapping one variable-length sequence of symbol representations\\n(x1;:::;x n)to another sequence of equal length (z1;:::;z n), withxi;zi2Rd, such as a hidden\\nlayer in a typical sequence transduction encoder or decoder. Motivating our use of self-attention we\\nconsider three desiderata.\\nOne is the total computational complexity per layer. Another is the amount of computation that can\\nbe parallelized, as measured by the minimum number of sequential operations required.\\nThe third is the path length between long-range dependencies in the network. Learning long-range\\ndependencies is a key challenge in many sequence transduction tasks. One key factor affecting the\\nability to learn such dependencies is the length of the paths forward and backward signals have to'"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "texts[20]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "2f908206",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<bound method OpenAIEmbeddings.embed_query of OpenAIEmbeddings(client=<class 'openai.api_resources.embedding.Embedding'>, model='text-embedding-ada-002', deployment='text-embedding-ada-002', embedding_ctx_length=8191, openai_api_key=None, openai_organization=None, allowed_special=set(), disallowed_special='all', chunk_size=1000, max_retries=6)>"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Download embeddings from OpenAI\n",
    "embeddings = OpenAIEmbeddings()\n",
    "docsearch = FAISS.from_texts(texts, embeddings)\n",
    "docsearch.embedding_function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "dfa8864b",
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'RetrievalQA' object has no attribute 'llm_chain'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[15], line 12\u001b[0m\n\u001b[0;32m      7\u001b[0m rqa \u001b[38;5;241m=\u001b[39m RetrievalQA\u001b[38;5;241m.\u001b[39mfrom_chain_type(llm\u001b[38;5;241m=\u001b[39mOpenAI(), \n\u001b[0;32m      8\u001b[0m                                   chain_type\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mstuff\u001b[39m\u001b[38;5;124m\"\u001b[39m, \n\u001b[0;32m      9\u001b[0m                                   retriever\u001b[38;5;241m=\u001b[39mretriever, \n\u001b[0;32m     10\u001b[0m                                   return_source_documents\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[0;32m     11\u001b[0m \u001b[38;5;66;03m# check the prompt\u001b[39;00m\n\u001b[1;32m---> 12\u001b[0m \u001b[43mrqa\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mllm_chain\u001b[49m\u001b[38;5;241m.\u001b[39mprompt\u001b[38;5;241m.\u001b[39mtemplate\n",
      "\u001b[1;31mAttributeError\u001b[0m: 'RetrievalQA' object has no attribute 'llm_chain'"
     ]
    }
   ],
   "source": [
    "from langchain.chains import RetrievalQA\n",
    "from langchain.llms import OpenAI\n",
    "# set up FAISS as a generic retriever \n",
    "retriever = docsearch.as_retriever(search_type=\"similarity\", search_kwargs={\"k\":4})\n",
    "\n",
    "# create the chain to answer questions \n",
    "rqa = RetrievalQA.from_chain_type(llm=OpenAI(), \n",
    "                                  chain_type=\"stuff\", \n",
    "                                  retriever=retriever, \n",
    "                                  return_source_documents=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "a112fe83",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "' Self-attention is used to help learn long-range dependencies in a network by reducing the path length between long-range dependencies.'"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "query = \"What is the main purpose of self-attention in simple terms?\"\n",
    "rqa(query)['result']"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pdfreader",
   "language": "python",
   "name": "pdfreader"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
